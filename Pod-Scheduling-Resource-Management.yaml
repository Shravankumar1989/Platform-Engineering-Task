apiVersion: v1
kind: Pod
metadata:
  name: prod-gpu-pod
  labels:
    app: gpu-application
spec:
  # Pod scheduling requirements
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: env
            operator: In
            values:
            - prod
          - key: nvidia.com/gpu
            operator: Exists
  
  # Prevent eviction under memory pressure
  priorityClassName: high-priority
  
  # Make this pod non-evictable under memory pressure
  terminationGracePeriodSeconds: 30
  
  containers:
  - name: gpu-container
    image: gpu-application:latest
    
    # Resource specifications
    resources:
      requests:
        memory: "500Mi"
        cpu: "250m"
        nvidia.com/gpu: 1
      limits:
        memory: "2Gi"
        cpu: "1"
        nvidia.com/gpu: 1
    
    # Mount secret volume
    volumeMounts:
    - name: app-secrets-volume
      mountPath: "/etc/app-secrets"
      readOnly: true
  
  # Secret volume definition
  volumes:
  - name: app-secrets-volume
    secret:
      secretName: app-secrets
  
  # Ensure the pod is not scheduled on nodes with taints that would reject it
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"

---
# Priority class definition (typically would be in a separate file)
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "This priority class should be used for pods that should not be evicted under memory pressure"